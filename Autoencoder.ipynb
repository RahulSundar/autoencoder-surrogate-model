{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Neural Networks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The autoencoder neural network is an unsupervised type of artificial neural network that learns to represent the data in a lower-dimensional space by encoding the data and then reconstructing the data back from the reduced space representation of the data. The autoencoder is trained to get an output as close as possible to its input. \n",
    "\n",
    "The autoencoder neural consists of three main parts:\n",
    "\n",
    "1. **Encoder**: The data input dimensions are reduced and then encoded into a lower-dimensional representation.\n",
    "2. **Bottleneck**: It is the layer where it contains the lowest dimensional representation of the input data in the neural network.\n",
    "3. **Decoder**: The original data is reconstructed from the encoded representation.\n",
    "\n",
    "A simple schema of an autoencoder neural network where its input is an image is presented below:\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\">\n",
    "  <figcaption>Fig.1 - Autoencoder [<a href=\"https://blog.keras.io/building-autoencoders-in-keras.html\">Keras</a>].</figcaption>\n",
    "</figure> \n",
    "\n",
    "The encoder and the decoder parts of the autoencoder neural network could be simply visualised as an encoder function $\\textbf{h} = f(\\textbf{x})$ and as a decoder function $\\textbf{x} = g(\\textbf{h})$. Thus, an autoencoder could simply be represented as $g(f(\\textbf{x})) = \\textbf{x}$. However, according to [Goodfellow et al. 2016](https://www.deeplearningbook.org/contents/autoencoders.html), the autoencoder neural networks have an generalised idea of an encoder and a decoder, where the encoder and decoder can be viewed as a stochastic mappings $p_{encoder}(\\textbf{h}|\\textbf{x})$ and $p_{decoder}(\\textbf{x}|\\textbf{h})$. Because the autoencoders are unable to learn to copy perfectly and they are restricted in ways that allows only to approximately copy the input data. The model during the training process is forced to determine which aspects of the input should be learned, and often useful properties of the\n",
    "data are learned.\n",
    "\n",
    "Traditionally, the autoencoders have been used for dimensionality reduction and feature learning. However, within the development of the generative modelling theoretical connections between autoencoders and latent variable models were found and brought the autoencoder as a competitive model of generative modelling.\n",
    "\n",
    "### Architectures\n",
    "\n",
    "The autoencoder neural network architecture is quite diverse. If it is possible to sequentially reduce and then expand the dimensions back to the original dimension, it is possible to obtain an autoencoder neural network. Therefore, some autoencoders use fully-connected, convolutional, LSTM, or a combination of then. The usage of each layer type depends on the problem that being tried to address.\n",
    "\n",
    "A different architecture that received quite atention recently are the architectures based on the Variational Autoencoder (VAE). These architectures are generative models and as mentioned by [Goodfellow et al. 2016](https://www.deeplearningbook.org/contents/autoencoders.html), they have a theoretical connections with latent variable models such as Generative Adversarial Networks (GAN).\n",
    "\n",
    "### Applications\n",
    "\n",
    "The autoencoders have a wide variety of applications such as dimensionality reduction [[Wang, et al. 2014](https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/papers/Wang_Generalized_Autoencoder_A_2014_CVPR_paper.pdf)], feature learning, anomaly detection [[Sakurada and Yairi 2014](https://dl.acm.org/doi/pdf/10.1145/2689746.2689747)], data denoising [[Vincent, et al. 2010](http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf)].\n",
    "\n",
    "Another application for the autoencoder is for generative modelling, where, for instance, images are generated by sampling data from reduced lower dimension space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development\n",
    "\n",
    "It is quite known in the neural network development the necessity to perform a hyperparameter optimisation. However, the training process of a single neural network can take hours depending on the architecture and the amount of data being trained. Therefore, this notebook will quickly assess different autoencoder neural network architectures with similar sizes to select the most promising architectures to perform a hyperparameter optimisation.\n",
    "\n",
    "For the sake of simplicity, it was created a Jupyter notebook for each architecture, where the training process can be followed. In this notebook the architectures will be loaded and the results will be compared.\n",
    "\n",
    "The architectures evaluated were: \n",
    "1. [Convolutional autoencoder](./tests/jupyter-notebooks/train_ae_conv.ipynb);\n",
    "1. [Convolutional autoencoder with dropout](./tests/jupyter-notebooks/train_ae_conv_drop.ipynb);\n",
    "1. [VQ-VAE-2 based autoencoder](./tests/jupyter-notebooks/train_ae_add.ipynb);\n",
    "1. [Depthwise convolutional autoencoder](./tests/jupyter-notebooks/train_ae_depth.ipynb);\n",
    "1. [Dual convolutional autoencoder](./tests/jupyter-notebooks/train_dual_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary steps\n",
    "\n",
    "Import modules and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import h5py\n",
    "import keras.layers as layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "from utils import plot_red_comp, slicer, split\n",
    "from utils_keras import loss_norm_error, loss_norm_error_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets to load\n",
    "dt_fl = \"nn_data.h5\"\n",
    "dt_dst = \"scaled_data\"\n",
    "\n",
    "# Open data file\n",
    "f = h5py.File(dt_fl, \"r\")\n",
    "dt = f[dt_dst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional autoencoder with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQ-VAE-2 based autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depthwise convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda4a250c8e9e664b18ad36b699d1ca8e02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
